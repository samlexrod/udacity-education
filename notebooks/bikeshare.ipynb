{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bikeshare Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from src import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.\n",
    "\n",
    "Data Fields\n",
    "- datetime - hourly date + timestamp  \n",
    "- season \n",
    "    - 1 = spring, \n",
    "    - 2 = summer, \n",
    "    - 3 = fall, \n",
    "    - 4 = winter \n",
    "- holiday - whether the day is considered a holiday\n",
    "- workingday - whether the day is neither a weekend nor holiday\n",
    "- weather \n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "- temp - temperature in Celsius\n",
    "- atemp - \"feels like\" temperature in Celsius\n",
    "- humidity - relative humidity\n",
    "- windspeed - wind speed\n",
    "- casual - number of non-registered user rentals initiated\n",
    "- registered - number of registered user rentals initiated\n",
    "- count - number of total rentals <- PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without Using Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Data Loader initialized with data path: {self.data_path}\n",
      "            - Use load_raw() to load raw data\n",
      "            - Use get_train_test_data() to get raw train and test data  \n",
      "            - Use save_feature_engineered_data() to save feature engineered data\n",
      "            - Use load_feature_engineered() to load feature engineered data\n",
      "              \n",
      "            - Use set_as_category() to set columns as category\n",
      "        \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'get_raw_train_test_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Loading raw trained and test data to process without any changes\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_raw_train_test_data\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'get_raw_train_test_data'"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "\n",
    "# Loading raw trained and test data to process without any changes\n",
    "train_df, test_df = loader.get_raw_train_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Training without New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:12:58 PDT 2024; root:xnu-10063.121.3~5/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.72 GB / 16.00 GB (17.0%)\n",
      "Disk Space Avail:   22.01 GB / 460.43 GB (4.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "2024-07-22 21:21:36,810\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"autogluon/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 150s\n",
      "AutoGluon will save models to \"autogluon/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    9676\n",
      "Train Data Columns: 11\n",
      "Label Column:       count\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2801.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.44 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                        : 7 | ['season', 'holiday', 'workingday', 'weather', 'humidity', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['datetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 5 | ['season', 'weather', 'humidity', 'casual', 'registered']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.0s = Fit runtime\n",
      "\t11 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 99.63s of the 149.47s of remaining time.\n",
      "\t-107.3513\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 98.4s of the 148.25s of remaining time.\n",
      "\t-89.9096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 98.37s of the 148.22s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.59844\n",
      "[2000]\tvalid_set's rmse: 5.06757\n",
      "[3000]\tvalid_set's rmse: 4.87535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3187. Best iteration is:\n",
      "\t[3162]\tvalid_set's rmse: 4.84423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.59925\n",
      "[2000]\tvalid_set's rmse: 5.06547\n",
      "[3000]\tvalid_set's rmse: 4.89408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3788. Best iteration is:\n",
      "\t[3788]\tvalid_set's rmse: 4.83114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.73848\n",
      "[2000]\tvalid_set's rmse: 5.2462\n",
      "[3000]\tvalid_set's rmse: 5.05485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3872. Best iteration is:\n",
      "\t[3870]\tvalid_set's rmse: 4.96871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.69305\n",
      "[2000]\tvalid_set's rmse: 4.18485\n",
      "[3000]\tvalid_set's rmse: 4.02804\n",
      "[4000]\tvalid_set's rmse: 3.96055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4213. Best iteration is:\n",
      "\t[4209]\tvalid_set's rmse: 3.94931\n",
      "\tRan out of time, early stopping on iteration 817. Best iteration is:\n",
      "\t[817]\tvalid_set's rmse: 5.98286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.40893\n",
      "[2000]\tvalid_set's rmse: 4.89384\n",
      "[3000]\tvalid_set's rmse: 4.70979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3965. Best iteration is:\n",
      "\t[3965]\tvalid_set's rmse: 4.61553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.32442\n",
      "[2000]\tvalid_set's rmse: 4.68609\n",
      "[3000]\tvalid_set's rmse: 4.46323\n",
      "[4000]\tvalid_set's rmse: 4.34373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4266. Best iteration is:\n",
      "\t[4264]\tvalid_set's rmse: 4.31853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1656. Best iteration is:\n",
      "\t[1656]\tvalid_set's rmse: 5.82433\n",
      "\t-4.9592\t = Validation score   (-root_mean_squared_error)\n",
      "\t93.47s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3.62s of the 53.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 103. Best iteration is:\n",
      "\t[103]\tvalid_set's rmse: 3.82403\n",
      "\tRan out of time, early stopping on iteration 109. Best iteration is:\n",
      "\t[109]\tvalid_set's rmse: 3.58619\n",
      "\tRan out of time, early stopping on iteration 113. Best iteration is:\n",
      "\t[113]\tvalid_set's rmse: 4.00064\n",
      "\tRan out of time, early stopping on iteration 118. Best iteration is:\n",
      "\t[118]\tvalid_set's rmse: 3.84324\n",
      "\tRan out of time, early stopping on iteration 123. Best iteration is:\n",
      "\t[123]\tvalid_set's rmse: 3.49426\n",
      "\tRan out of time, early stopping on iteration 116. Best iteration is:\n",
      "\t[116]\tvalid_set's rmse: 3.56923\n",
      "\tRan out of time, early stopping on iteration 131. Best iteration is:\n",
      "\t[131]\tvalid_set's rmse: 2.95128\n",
      "\tRan out of time, early stopping on iteration 160. Best iteration is:\n",
      "\t[160]\tvalid_set's rmse: 4.49534\n",
      "\t-3.7438\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 0.12s of the 49.96s of remaining time.\n",
      "\t-3.0656\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 149.48s of the 47.75s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.625, 'LightGBMXT_BAG_L1': 0.208, 'LightGBM_BAG_L1': 0.167}\n",
      "\t-2.7253\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 47.73s of the 47.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.10652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1767. Best iteration is:\n",
      "\t[1760]\tvalid_set's rmse: 3.86984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1866. Best iteration is:\n",
      "\t[1866]\tvalid_set's rmse: 4.32917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1897. Best iteration is:\n",
      "\t[1896]\tvalid_set's rmse: 3.8508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.00127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1960. Best iteration is:\n",
      "\t[1925]\tvalid_set's rmse: 3.75372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.7868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1860. Best iteration is:\n",
      "\t[1859]\tvalid_set's rmse: 4.48334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.43449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1952. Best iteration is:\n",
      "\t[1948]\tvalid_set's rmse: 4.10802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.30722\n",
      "[2000]\tvalid_set's rmse: 4.9276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2157. Best iteration is:\n",
      "\t[2157]\tvalid_set's rmse: 4.9023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.13195\n",
      "[2000]\tvalid_set's rmse: 4.88284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2319. Best iteration is:\n",
      "\t[2315]\tvalid_set's rmse: 4.87216\n",
      "\t-4.2921\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.33s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1.62s of the 1.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 25. Best iteration is:\n",
      "\t[25]\tvalid_set's rmse: 48.6021\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[29]\tvalid_set's rmse: 41.514\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[29]\tvalid_set's rmse: 41.7438\n",
      "\tRan out of time, early stopping on iteration 33. Best iteration is:\n",
      "\t[33]\tvalid_set's rmse: 33.5897\n",
      "\tRan out of time, early stopping on iteration 35. Best iteration is:\n",
      "\t[35]\tvalid_set's rmse: 30.4839\n",
      "\tRan out of time, early stopping on iteration 38. Best iteration is:\n",
      "\t[38]\tvalid_set's rmse: 26.2273\n",
      "\tRan out of time, early stopping on iteration 42. Best iteration is:\n",
      "\t[42]\tvalid_set's rmse: 21.4088\n",
      "\tRan out of time, early stopping on iteration 54. Best iteration is:\n",
      "\t[54]\tvalid_set's rmse: 12.1482\n",
      "\t-33.8773\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 149.48s of the -0.06s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.583, 'LightGBMXT_BAG_L1': 0.167, 'LightGBM_BAG_L1': 0.125, 'LightGBMXT_BAG_L2': 0.125}\n",
      "\t-2.6868\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 149.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1694.8 rows/s (1210 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3      -3.400523   -2.686793  root_mean_squared_error        1.177902       0.954470  144.054056                 0.001024                0.000195           0.010723            3       True          9\n",
      "1     WeightedEnsemble_L2      -3.447670   -2.725292  root_mean_squared_error        0.773300       0.659275   98.716101                 0.001999                0.000214           0.014241            2       True          6\n",
      "2  RandomForestMSE_BAG_L1      -3.576009   -3.065597  root_mean_squared_error        0.150132       0.229492    1.781304                 0.150132                0.229492           1.781304            1       True          5\n",
      "3       LightGBMXT_BAG_L2      -4.228792   -4.292056  root_mean_squared_error        1.176877       0.954275  144.043333                 0.372722                0.250003          45.329786            2       True          7\n",
      "4         LightGBM_BAG_L1      -4.455557   -3.743808  root_mean_squared_error        0.026307       0.012895    3.452591                 0.026307                0.012895           3.452591            1       True          4\n",
      "5       LightGBMXT_BAG_L1      -4.570141   -4.959239  root_mean_squared_error        0.594862       0.416674   93.467965                 0.594862                0.416674          93.467965            1       True          3\n",
      "6         LightGBM_BAG_L2     -32.474864  -33.877345  root_mean_squared_error        0.819158       0.709663  100.256635                 0.015002                0.005391           1.543088            2       True          8\n",
      "7   KNeighborsDist_BAG_L1     -92.326969  -89.909634  root_mean_squared_error        0.016348       0.014710    0.004768                 0.016348                0.014710           0.004768            1       True          2\n",
      "8   KNeighborsUnif_BAG_L1    -109.825895 -107.351259  root_mean_squared_error        0.016506       0.030501    0.006919                 0.016506                0.030501           0.006919            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t151s\t = DyStack   runtime |\t449s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 449s\n",
      "AutoGluon will save models to \"autogluon\"\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 11\n",
      "Label Column:       count\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2934.10 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.62 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                        : 7 | ['season', 'holiday', 'workingday', 'weather', 'humidity', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['datetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 5 | ['season', 'weather', 'humidity', 'casual', 'registered']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.0s = Fit runtime\n",
      "\t11 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 298.97s of the 448.56s of remaining time.\n",
      "\t-101.5882\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 298.92s of the 448.52s of remaining time.\n",
      "\t-84.1464\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 298.88s of the 448.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.49623\n",
      "[2000]\tvalid_set's rmse: 4.95796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2544. Best iteration is:\n",
      "\t[2544]\tvalid_set's rmse: 4.82457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.11999\n",
      "[2000]\tvalid_set's rmse: 4.59468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2121. Best iteration is:\n",
      "\t[2120]\tvalid_set's rmse: 4.56518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.3011\n",
      "[2000]\tvalid_set's rmse: 4.8016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2658. Best iteration is:\n",
      "\t[2657]\tvalid_set's rmse: 4.64694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.70043\n",
      "[2000]\tvalid_set's rmse: 5.06431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2376. Best iteration is:\n",
      "\t[2374]\tvalid_set's rmse: 4.97129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.9318\n",
      "[2000]\tvalid_set's rmse: 4.53065\n",
      "[3000]\tvalid_set's rmse: 4.36655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3714. Best iteration is:\n",
      "\t[3712]\tvalid_set's rmse: 4.31695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.5316\n",
      "[2000]\tvalid_set's rmse: 4.97629\n",
      "[3000]\tvalid_set's rmse: 4.76847\n",
      "[4000]\tvalid_set's rmse: 4.65328\n",
      "[5000]\tvalid_set's rmse: 4.5874\n",
      "[6000]\tvalid_set's rmse: 4.545\n",
      "[7000]\tvalid_set's rmse: 4.51808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 7946. Best iteration is:\n",
      "\t[7875]\tvalid_set's rmse: 4.50131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.82667\n",
      "[2000]\tvalid_set's rmse: 4.30572\n",
      "[3000]\tvalid_set's rmse: 4.12467\n",
      "[4000]\tvalid_set's rmse: 4.04927\n",
      "[5000]\tvalid_set's rmse: 3.98569\n",
      "[6000]\tvalid_set's rmse: 3.94082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 6822. Best iteration is:\n",
      "\t[6786]\tvalid_set's rmse: 3.92308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.00473\n",
      "[2000]\tvalid_set's rmse: 4.32034\n",
      "[3000]\tvalid_set's rmse: 4.0569\n",
      "[4000]\tvalid_set's rmse: 3.92353\n",
      "[5000]\tvalid_set's rmse: 3.85477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5072. Best iteration is:\n",
      "\t[5072]\tvalid_set's rmse: 3.84994\n",
      "\t-4.4657\t = Validation score   (-root_mean_squared_error)\n",
      "\t285.62s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 11.43s of the 161.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 72. Best iteration is:\n",
      "\t[72]\tvalid_set's rmse: 6.39759\n",
      "\tRan out of time, early stopping on iteration 86. Best iteration is:\n",
      "\t[86]\tvalid_set's rmse: 4.8815\n",
      "\tRan out of time, early stopping on iteration 77. Best iteration is:\n",
      "\t[77]\tvalid_set's rmse: 5.91596\n",
      "\tRan out of time, early stopping on iteration 92. Best iteration is:\n",
      "\t[92]\tvalid_set's rmse: 4.52056\n",
      "\tRan out of time, early stopping on iteration 91. Best iteration is:\n",
      "\t[91]\tvalid_set's rmse: 4.66909\n",
      "\tRan out of time, early stopping on iteration 97. Best iteration is:\n",
      "\t[97]\tvalid_set's rmse: 3.92226\n",
      "\tRan out of time, early stopping on iteration 92. Best iteration is:\n",
      "\t[92]\tvalid_set's rmse: 3.51124\n",
      "\tRan out of time, early stopping on iteration 122. Best iteration is:\n",
      "\t[122]\tvalid_set's rmse: 2.99725\n",
      "\t-4.7263\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.95s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 0.42s of the 150.02s of remaining time.\n",
      "\t-2.818\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.92s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 147.59s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.75, 'LightGBMXT_BAG_L1': 0.25}\n",
      "\t-2.5187\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 147.58s of the 147.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.48606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1093. Best iteration is:\n",
      "\t[1093]\tvalid_set's rmse: 4.42391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.49246\n",
      "[2000]\tvalid_set's rmse: 5.13932\n",
      "[3000]\tvalid_set's rmse: 5.03329\n",
      "[4000]\tvalid_set's rmse: 5.00552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4674. Best iteration is:\n",
      "\t[4558]\tvalid_set's rmse: 4.98158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.29517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1268. Best iteration is:\n",
      "\t[1267]\tvalid_set's rmse: 4.11795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.81265\n",
      "[2000]\tvalid_set's rmse: 4.38331\n",
      "[3000]\tvalid_set's rmse: 4.29044\n",
      "[4000]\tvalid_set's rmse: 4.25449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5017. Best iteration is:\n",
      "\t[4202]\tvalid_set's rmse: 4.24878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\tvalid_set's rmse: 4.26109\n",
      "[1000]\tvalid_set's rmse: 4.47474\n",
      "[2000]\tvalid_set's rmse: 4.28658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2656. Best iteration is:\n",
      "\t[2542]\tvalid_set's rmse: 4.26297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.6344\n",
      "[2000]\tvalid_set's rmse: 4.29957\n",
      "[3000]\tvalid_set's rmse: 4.1345\n",
      "[4000]\tvalid_set's rmse: 4.07097\n",
      "[5000]\tvalid_set's rmse: 4.02682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5857. Best iteration is:\n",
      "\t[5800]\tvalid_set's rmse: 3.99784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.18392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1365. Best iteration is:\n",
      "\t[1364]\tvalid_set's rmse: 4.07552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.47659\n",
      "[2000]\tvalid_set's rmse: 4.21038\n",
      "[3000]\tvalid_set's rmse: 4.10809\n",
      "[4000]\tvalid_set's rmse: 4.05249\n",
      "[5000]\tvalid_set's rmse: 4.02098\n",
      "[6000]\tvalid_set's rmse: 3.99483\n",
      "[7000]\tvalid_set's rmse: 3.97811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 7923. Best iteration is:\n",
      "\t[7915]\tvalid_set's rmse: 3.95948\n",
      "\t-4.2697\t = Validation score   (-root_mean_squared_error)\n",
      "\t140.91s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 5.05s of the 5.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 125. Best iteration is:\n",
      "\t[124]\tvalid_set's rmse: 3.15529\n",
      "\tRan out of time, early stopping on iteration 116. Best iteration is:\n",
      "\t[116]\tvalid_set's rmse: 3.57582\n",
      "\tRan out of time, early stopping on iteration 132. Best iteration is:\n",
      "\t[132]\tvalid_set's rmse: 2.55042\n",
      "\tRan out of time, early stopping on iteration 121. Best iteration is:\n",
      "\t[121]\tvalid_set's rmse: 3.20589\n",
      "\tRan out of time, early stopping on iteration 153. Best iteration is:\n",
      "\t[153]\tvalid_set's rmse: 3.07068\n",
      "\tRan out of time, early stopping on iteration 161. Best iteration is:\n",
      "\t[159]\tvalid_set's rmse: 2.71488\n",
      "\tRan out of time, early stopping on iteration 174. Best iteration is:\n",
      "\t[145]\tvalid_set's rmse: 2.67135\n",
      "\tRan out of time, early stopping on iteration 196. Best iteration is:\n",
      "\t[194]\tvalid_set's rmse: 2.51752\n",
      "\t-2.9538\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 0.06s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.571, 'LightGBM_BAG_L2': 0.19, 'LightGBMXT_BAG_L1': 0.143, 'LightGBMXT_BAG_L2': 0.095}\n",
      "\t-2.4474\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 448.59s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 993.5 rows/s (1361 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "        label='count',\n",
    "        path='autogluon',\n",
    "        eval_metric='root_mean_squared_error',\n",
    "    ).fit(\n",
    "        train_df,\n",
    "        time_limit=600,\n",
    "        presets='best_quality'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Showing the Leatherboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-54.569714</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.292876</td>\n",
       "      <td>443.947090</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-54.586355</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.010519</td>\n",
       "      <td>318.299719</td>\n",
       "      <td>0.039332</td>\n",
       "      <td>20.634286</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-60.570375</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.253296</td>\n",
       "      <td>423.301549</td>\n",
       "      <td>0.282109</td>\n",
       "      <td>125.636116</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-84.146423</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-84.146423</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.021625</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-101.588176</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-116.542032</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.241228</td>\n",
       "      <td>1.870387</td>\n",
       "      <td>0.241228</td>\n",
       "      <td>1.870387</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-131.432362</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.088231</td>\n",
       "      <td>39.867387</td>\n",
       "      <td>0.088231</td>\n",
       "      <td>39.867387</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-131.494795</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.612940</td>\n",
       "      <td>255.911016</td>\n",
       "      <td>0.612940</td>\n",
       "      <td>255.911016</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   score_val              eval_metric  pred_time_val  \\\n",
       "0     WeightedEnsemble_L3  -54.569714  root_mean_squared_error       1.292876   \n",
       "1         LightGBM_BAG_L2  -54.586355  root_mean_squared_error       1.010519   \n",
       "2       LightGBMXT_BAG_L2  -60.570375  root_mean_squared_error       1.253296   \n",
       "3   KNeighborsDist_BAG_L1  -84.146423  root_mean_squared_error       0.014645   \n",
       "4     WeightedEnsemble_L2  -84.146423  root_mean_squared_error       0.014847   \n",
       "5   KNeighborsUnif_BAG_L1 -101.588176  root_mean_squared_error       0.014143   \n",
       "6  RandomForestMSE_BAG_L1 -116.542032  root_mean_squared_error       0.241228   \n",
       "7         LightGBM_BAG_L1 -131.432362  root_mean_squared_error       0.088231   \n",
       "8       LightGBMXT_BAG_L1 -131.494795  root_mean_squared_error       0.612940   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  443.947090                0.000248           0.011255            3   \n",
       "1  318.299719                0.039332          20.634286            2   \n",
       "2  423.301549                0.282109         125.636116            2   \n",
       "3    0.009696                0.014645           0.009696            1   \n",
       "4    0.021625                0.000202           0.011929            2   \n",
       "5    0.006946                0.014143           0.006946            1   \n",
       "6    1.870387                0.241228           1.870387            1   \n",
       "7   39.867387                0.088231          39.867387            1   \n",
       "8  255.911016                0.612940         255.911016            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True          9  \n",
       "1       True          8  \n",
       "2       True          7  \n",
       "3       True          2  \n",
       "4       True          6  \n",
       "5       True          1  \n",
       "6       True          5  \n",
       "7       True          4  \n",
       "8       True          3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(predictor.leaderboard(silent=True))\n",
    "except:\n",
    "    predictor = TabularPredictor.load('autogluon')\n",
    "    display(predictor.leaderboard(silent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    34.273094\n",
       "1    43.230057\n",
       "2    46.590622\n",
       "3    50.979973\n",
       "4    51.777607\n",
       "Name: count, dtype: float32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictor.predict(test_df)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6493.000000\n",
       "mean       98.326591\n",
       "std        88.796036\n",
       "min       -10.711480\n",
       "25%        16.453503\n",
       "50%        62.550030\n",
       "75%       169.153320\n",
       "max       370.938568\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying negative predictions\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 negative predictions to set to zero.\n"
     ]
    }
   ],
   "source": [
    "# Counting negative predictions\n",
    "negative_prediction_count = (predictions < 0).sum()\n",
    "\n",
    "print(f\"There are {negative_prediction_count} negative predictions to set to zero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Setting up for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6493.000000\n",
       "mean       98.332489\n",
       "std        88.789307\n",
       "min         0.000000\n",
       "25%        16.453503\n",
       "50%        62.550030\n",
       "75%       169.153320\n",
       "max       370.938568\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting negative predictions to zero\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  count\n",
       "0  2011-01-20 00:00:00      0\n",
       "1  2011-01-20 01:00:00      0\n",
       "2  2011-01-20 02:00:00      0\n",
       "3  2011-01-20 03:00:00      0\n",
       "4  2011-01-20 04:00:00      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6493, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('../data/sampleSubmission.csv')\n",
    "display(submission_df.head())\n",
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>34.273094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>43.230057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>46.590622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>50.979973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>51.777607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime      count\n",
       "0  2011-01-20 00:00:00  34.273094\n",
       "1  2011-01-20 01:00:00  43.230057\n",
       "2  2011-01-20 02:00:00  46.590622\n",
       "3  2011-01-20 03:00:00  50.979973\n",
       "4  2011-01-20 04:00:00  51.777607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6493, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['count'] = predictions\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df.head())\n",
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Submitting Initial Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L3'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the best model name\n",
    "best_model = predictor.model_best\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 188k/188k [00:00<00:00, 436kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m f\"irst submission with {best_model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName        date                 description                                status    publicScore  privateScore  \n",
      "--------------  -------------------  -----------------------------------------  --------  -----------  ------------  \n",
      "submission.csv  2024-07-07 21:14:45  first submission with WeightedEnsemble_L3  complete  1.84764      1.84764       \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Extract Feature Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Data Loader initialized with data path: ../data/\n",
      "            - Use load_raw() to load raw data\n",
      "            - Use get_train_test_data() to get raw train and test data  \n",
      "            - Use save_feature_engineered_data() to save feature engineered data\n",
      "            - Use load_feature_engineered() to load feature engineered data\n",
      "              \n",
      "            - Use set_as_category() to set columns as category\n",
      "\n",
      "        Checkpoints available: ['hyperparameter_tuning']\n",
      "        \n",
      "Columns ['season', 'weather'] set as category successfully!\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "loader.load_raw()\n",
    "\n",
    "# Loading raw trained and test data with changes to the season and weather columns\n",
    "loader.set_as_category(columns=[\"season\", \"weather\"])\n",
    "train_df, test_df = loader.get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime        object\n",
       "season        category\n",
       "holiday          int64\n",
       "workingday       int64\n",
       "weather       category\n",
       "temp           float64\n",
       "atemp          float64\n",
       "humidity         int64\n",
       "windspeed      float64\n",
       "casual           int64\n",
       "registered       int64\n",
       "count            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Re-training the model with categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon-new-features\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:12:58 PDT 2024; root:xnu-10063.121.3~5/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.77 GB / 16.00 GB (23.6%)\n",
      "Disk Space Avail:   38.90 GB / 460.43 GB (8.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"autogluon-new-features/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 150s\n",
      "AutoGluon will save models to \"autogluon-new-features/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    9676\n",
      "Train Data Columns: 9\n",
      "Label Column:       count\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3853.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.16 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                   : 2 | ['season', 'weather']\n",
      "\t\t('float', [])                      : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                        : 3 | ['holiday', 'workingday', 'humidity']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['datetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 2 | ['season', 'weather']\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 1 | ['humidity']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.70 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 99.93s of the 149.92s of remaining time.\n",
      "\t-107.3513\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 99.77s of the 149.77s of remaining time.\n",
      "\t-89.9096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 99.75s of the 149.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 129.884\n",
      "[2000]\tvalid_set's rmse: 129.338\n",
      "[1000]\tvalid_set's rmse: 129.41\n",
      "[2000]\tvalid_set's rmse: 128.542\n",
      "[1000]\tvalid_set's rmse: 132.736\n",
      "[2000]\tvalid_set's rmse: 132.145\n",
      "[1000]\tvalid_set's rmse: 126.902\n",
      "[2000]\tvalid_set's rmse: 125.608\n",
      "[3000]\tvalid_set's rmse: 125.013\n",
      "[1000]\tvalid_set's rmse: 134.952\n",
      "[2000]\tvalid_set's rmse: 134.183\n",
      "[3000]\tvalid_set's rmse: 133.455\n",
      "[4000]\tvalid_set's rmse: 133.177\n",
      "[5000]\tvalid_set's rmse: 132.541\n",
      "[6000]\tvalid_set's rmse: 132.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 6371. Best iteration is:\n",
      "\t[6303]\tvalid_set's rmse: 132.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 137.272\n",
      "[2000]\tvalid_set's rmse: 135.531\n",
      "[3000]\tvalid_set's rmse: 134.963\n",
      "[4000]\tvalid_set's rmse: 134.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4317. Best iteration is:\n",
      "\t[4013]\tvalid_set's rmse: 134.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 138.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1469. Best iteration is:\n",
      "\t[1454]\tvalid_set's rmse: 137.466\n",
      "\t-131.5702\t = Validation score   (-root_mean_squared_error)\n",
      "\t93.49s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 5.08s of the 55.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 135. Best iteration is:\n",
      "\t[133]\tvalid_set's rmse: 133.151\n",
      "\tRan out of time, early stopping on iteration 139. Best iteration is:\n",
      "\t[139]\tvalid_set's rmse: 131.762\n",
      "\tRan out of time, early stopping on iteration 147. Best iteration is:\n",
      "\t[146]\tvalid_set's rmse: 134.477\n",
      "\tRan out of time, early stopping on iteration 144. Best iteration is:\n",
      "\t[144]\tvalid_set's rmse: 133.458\n",
      "\tRan out of time, early stopping on iteration 163. Best iteration is:\n",
      "\t[163]\tvalid_set's rmse: 129.419\n",
      "\tRan out of time, early stopping on iteration 177. Best iteration is:\n",
      "\t[176]\tvalid_set's rmse: 137.4\n",
      "\tRan out of time, early stopping on iteration 205. Best iteration is:\n",
      "\t[204]\tvalid_set's rmse: 137.307\n",
      "\tRan out of time, early stopping on iteration 221. Best iteration is:\n",
      "\t[215]\tvalid_set's rmse: 139.33\n",
      "\t-134.5727\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.83s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 0.17s of the 50.17s of remaining time.\n",
      "\t-119.5418\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 149.93s of the 48.18s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 1.0}\n",
      "\t-89.9096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 48.16s of the 48.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 67.7535\n",
      "[1000]\tvalid_set's rmse: 71.466\n",
      "[1000]\tvalid_set's rmse: 77.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1886. Best iteration is:\n",
      "\t[1475]\tvalid_set's rmse: 77.3103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 73.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1694. Best iteration is:\n",
      "\t[1307]\tvalid_set's rmse: 72.7247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 77.2509\n",
      "[2000]\tvalid_set's rmse: 77.213\n",
      "[1000]\tvalid_set's rmse: 76.8031\n",
      "[1000]\tvalid_set's rmse: 71.208\n",
      "[1000]\tvalid_set's rmse: 74.4012\n",
      "[2000]\tvalid_set's rmse: 74.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-73.4828\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.79s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 8.77s of the 8.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 270. Best iteration is:\n",
      "\t[138]\tvalid_set's rmse: 62.1571\n",
      "\tRan out of time, early stopping on iteration 282. Best iteration is:\n",
      "\t[142]\tvalid_set's rmse: 64.232\n",
      "\tRan out of time, early stopping on iteration 255. Best iteration is:\n",
      "\t[140]\tvalid_set's rmse: 69.0506\n",
      "\tRan out of time, early stopping on iteration 305. Best iteration is:\n",
      "\t[201]\tvalid_set's rmse: 68.6755\n",
      "\tRan out of time, early stopping on iteration 321. Best iteration is:\n",
      "\t[120]\tvalid_set's rmse: 68.2802\n",
      "\tRan out of time, early stopping on iteration 346. Best iteration is:\n",
      "\t[124]\tvalid_set's rmse: 70.9228\n",
      "\tRan out of time, early stopping on iteration 386. Best iteration is:\n",
      "\t[129]\tvalid_set's rmse: 64.8472\n",
      "\t-67.2912\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 149.93s of the 0.39s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.96, 'LightGBMXT_BAG_L2': 0.04}\n",
      "\t-67.2911\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 149.63s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1800.2 rows/s (1210 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon-new-features/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3     -68.646127  -67.291084  root_mean_squared_error        1.162087       0.963913  146.830132                 0.000660                0.000183           0.008744            3       True          9\n",
      "1         LightGBM_BAG_L2     -68.747538  -67.291184  root_mean_squared_error        0.890051       0.780237  108.033421                 0.038307                0.023131           8.220200            2       True          8\n",
      "2       LightGBMXT_BAG_L2     -70.842185  -73.482757  root_mean_squared_error        1.123120       0.940599  138.601188                 0.271376                0.183493          38.787967            2       True          7\n",
      "3   KNeighborsDist_BAG_L1     -92.326969  -89.909634  root_mean_squared_error        0.015759       0.015697    0.003692                 0.015759                0.015697           0.003692            1       True          2\n",
      "4     WeightedEnsemble_L2     -92.326969  -89.909634  root_mean_squared_error        0.017571       0.015880    0.011855                 0.001812                0.000183           0.008163            2       True          6\n",
      "5   KNeighborsUnif_BAG_L1    -109.825895 -107.351259  root_mean_squared_error        0.016146       0.041076    0.005488                 0.016146                0.041076           0.005488            1       True          1\n",
      "6  RandomForestMSE_BAG_L1    -118.473852 -119.541847  root_mean_squared_error        0.228596       0.276499    1.484524                 0.228596                0.276499           1.484524            1       True          5\n",
      "7       LightGBMXT_BAG_L1    -131.173695 -131.570227  root_mean_squared_error        0.551554       0.397919   93.487978                 0.551554                0.397919          93.487978            1       True          3\n",
      "8         LightGBM_BAG_L1    -133.347925 -134.572706  root_mean_squared_error        0.039689       0.025915    4.831538                 0.039689                0.025915           4.831538            1       True          4\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t151s\t = DyStack   runtime |\t449s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 449s\n",
      "AutoGluon will save models to \"autogluon-new-features\"\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 9\n",
      "Label Column:       count\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3769.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.31 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                   : 2 | ['season', 'weather']\n",
      "\t\t('float', [])                      : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                        : 3 | ['holiday', 'workingday', 'humidity']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['datetime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 2 | ['season', 'weather']\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 1 | ['humidity']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.79 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 299.33s of the 449.11s of remaining time.\n",
      "\t-101.5882\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 299.29s of the 449.06s of remaining time.\n",
      "\t-84.1464\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 299.25s of the 449.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 130.813\n",
      "[2000]\tvalid_set's rmse: 130.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2124. Best iteration is:\n",
      "\t[1761]\tvalid_set's rmse: 130.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 135.055\n",
      "[1000]\tvalid_set's rmse: 132.863\n",
      "[2000]\tvalid_set's rmse: 131.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2457. Best iteration is:\n",
      "\t[2451]\tvalid_set's rmse: 131.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 127.258\n",
      "[2000]\tvalid_set's rmse: 126.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2519. Best iteration is:\n",
      "\t[2492]\tvalid_set's rmse: 126.443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 133.682\n",
      "[2000]\tvalid_set's rmse: 132.057\n",
      "[3000]\tvalid_set's rmse: 130.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3912. Best iteration is:\n",
      "\t[3830]\tvalid_set's rmse: 130.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 134.515\n",
      "[2000]\tvalid_set's rmse: 133.869\n",
      "[1000]\tvalid_set's rmse: 133.908\n",
      "[2000]\tvalid_set's rmse: 132.57\n",
      "[3000]\tvalid_set's rmse: 132.156\n",
      "[4000]\tvalid_set's rmse: 131.909\n",
      "[5000]\tvalid_set's rmse: 131.895\n",
      "[1000]\tvalid_set's rmse: 132.398\n",
      "[2000]\tvalid_set's rmse: 131.476\n",
      "[3000]\tvalid_set's rmse: 131.125\n",
      "[4000]\tvalid_set's rmse: 131.208\n",
      "[5000]\tvalid_set's rmse: 131.066\n",
      "[6000]\tvalid_set's rmse: 131.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-131.3015\t = Validation score   (-root_mean_squared_error)\n",
      "\t252.02s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 45.89s of the 195.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 432. Best iteration is:\n",
      "\t[426]\tvalid_set's rmse: 130.478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 133.028\n",
      "[1000]\tvalid_set's rmse: 131.187\n",
      "[1000]\tvalid_set's rmse: 126.598\n",
      "[1000]\tvalid_set's rmse: 130.79\n",
      "[2000]\tvalid_set's rmse: 130.757\n",
      "[1000]\tvalid_set's rmse: 133.168\n",
      "[1000]\tvalid_set's rmse: 131.157\n",
      "[1000]\tvalid_set's rmse: 130.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-130.7397\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.12s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 11.3s of the 161.07s of remaining time.\n",
      "\t-116.6309\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.66s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 9.15s of the 158.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 375.\n",
      "\tRan out of time, early stopping on iteration 414.\n",
      "\tRan out of time, early stopping on iteration 422.\n",
      "\tRan out of time, early stopping on iteration 427.\n",
      "\tRan out of time, early stopping on iteration 417.\n",
      "\tRan out of time, early stopping on iteration 469.\n",
      "\tRan out of time, early stopping on iteration 512.\n",
      "\tRan out of time, early stopping on iteration 613.\n",
      "\t-136.1294\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.74s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 0.35s of the 150.13s of remaining time.\n",
      "\t-124.6544\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 148.93s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 1.0}\n",
      "\t-84.1464\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 148.91s of the 148.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 61.5997\n",
      "[2000]\tvalid_set's rmse: 60.5465\n",
      "[1000]\tvalid_set's rmse: 60.9525\n",
      "[2000]\tvalid_set's rmse: 59.5735\n",
      "[1000]\tvalid_set's rmse: 63.9217\n",
      "[2000]\tvalid_set's rmse: 62.6126\n",
      "[1000]\tvalid_set's rmse: 63.5466\n",
      "[2000]\tvalid_set's rmse: 62.6229\n",
      "[1000]\tvalid_set's rmse: 58.3412\n",
      "[2000]\tvalid_set's rmse: 57.0796\n",
      "[1000]\tvalid_set's rmse: 62.8921\n",
      "[2000]\tvalid_set's rmse: 61.8704\n",
      "[3000]\tvalid_set's rmse: 62.0382\n",
      "[1000]\tvalid_set's rmse: 64.4288\n",
      "[2000]\tvalid_set's rmse: 63.7549\n",
      "[1000]\tvalid_set's rmse: 58.7149\n",
      "[2000]\tvalid_set's rmse: 58.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-60.7416\t = Validation score   (-root_mean_squared_error)\n",
      "\t65.28s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 82.75s of the 82.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-54.6821\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.15s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 66.5s of the 66.48s of remaining time.\n",
      "\t-53.0126\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.13s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 60.88s of the 60.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 2369.\n",
      "\t-55.2169\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.99s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 10.82s of the 10.8s of remaining time.\n",
      "\t-53.6479\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 8.97s of the 8.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 0)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 0)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 0)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 0)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 1)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "\t-82.4083\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.0s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 0.59s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE_BAG_L2': 0.529, 'ExtraTreesMSE_BAG_L2': 0.294, 'LightGBM_BAG_L2': 0.118, 'CatBoost_BAG_L2': 0.059}\n",
      "\t-52.5096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 448.59s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1705.1 rows/s (1361 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon-new-features\")\n"
     ]
    }
   ],
   "source": [
    "predictor_new_features = TabularPredictor(\n",
    "    label='count',\n",
    "    path='autogluon-new-features',\n",
    "    eval_metric='root_mean_squared_error',\n",
    ").fit(\n",
    "    train_df,\n",
    "    time_limit=600,\n",
    "    presets='best_quality'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Showing the Leatherboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-52.509594</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.734140</td>\n",
       "      <td>369.858831</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-53.012627</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.400775</td>\n",
       "      <td>302.380536</td>\n",
       "      <td>0.279177</td>\n",
       "      <td>5.125411</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-53.647904</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.397926</td>\n",
       "      <td>298.586987</td>\n",
       "      <td>0.276328</td>\n",
       "      <td>1.331862</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-54.682144</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.162112</td>\n",
       "      <td>313.400169</td>\n",
       "      <td>0.040514</td>\n",
       "      <td>16.145044</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-55.216856</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.137912</td>\n",
       "      <td>347.241940</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>49.986816</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-60.741570</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.396845</td>\n",
       "      <td>362.531581</td>\n",
       "      <td>0.275247</td>\n",
       "      <td>65.276457</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-82.408300</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.325884</td>\n",
       "      <td>305.257513</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>8.002388</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-84.146423</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-84.146423</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.015391</td>\n",
       "      <td>0.016189</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-101.588176</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-116.630907</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.243608</td>\n",
       "      <td>1.659593</td>\n",
       "      <td>0.243608</td>\n",
       "      <td>1.659593</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-124.654425</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.239847</td>\n",
       "      <td>0.705708</td>\n",
       "      <td>0.239847</td>\n",
       "      <td>0.705708</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-130.739675</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.121490</td>\n",
       "      <td>34.121526</td>\n",
       "      <td>0.121490</td>\n",
       "      <td>34.121526</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-131.301459</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>252.018585</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>252.018585</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-136.129431</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.032935</td>\n",
       "      <td>8.737445</td>\n",
       "      <td>0.032935</td>\n",
       "      <td>8.737445</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model   score_val              eval_metric  \\\n",
       "0      WeightedEnsemble_L3  -52.509594  root_mean_squared_error   \n",
       "1   RandomForestMSE_BAG_L2  -53.012627  root_mean_squared_error   \n",
       "2     ExtraTreesMSE_BAG_L2  -53.647904  root_mean_squared_error   \n",
       "3          LightGBM_BAG_L2  -54.682144  root_mean_squared_error   \n",
       "4          CatBoost_BAG_L2  -55.216856  root_mean_squared_error   \n",
       "5        LightGBMXT_BAG_L2  -60.741570  root_mean_squared_error   \n",
       "6   NeuralNetFastAI_BAG_L2  -82.408300  root_mean_squared_error   \n",
       "7    KNeighborsDist_BAG_L1  -84.146423  root_mean_squared_error   \n",
       "8      WeightedEnsemble_L2  -84.146423  root_mean_squared_error   \n",
       "9    KNeighborsUnif_BAG_L1 -101.588176  root_mean_squared_error   \n",
       "10  RandomForestMSE_BAG_L1 -116.630907  root_mean_squared_error   \n",
       "11    ExtraTreesMSE_BAG_L1 -124.654425  root_mean_squared_error   \n",
       "12         LightGBM_BAG_L1 -130.739675  root_mean_squared_error   \n",
       "13       LightGBMXT_BAG_L1 -131.301459  root_mean_squared_error   \n",
       "14         CatBoost_BAG_L1 -136.129431  root_mean_squared_error   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0        1.734140  369.858831                0.000209           0.014574   \n",
       "1        1.400775  302.380536                0.279177           5.125411   \n",
       "2        1.397926  298.586987                0.276328           1.331862   \n",
       "3        1.162112  313.400169                0.040514          16.145044   \n",
       "4        1.137912  347.241940                0.016314          49.986816   \n",
       "5        1.396845  362.531581                0.275247          65.276457   \n",
       "6        1.325884  305.257513                0.204286           8.002388   \n",
       "7        0.014512    0.005741                0.014512           0.005741   \n",
       "8        0.015391    0.016189                0.000879           0.010448   \n",
       "9        0.015999    0.006527                0.015999           0.006527   \n",
       "10       0.243608    1.659593                0.243608           1.659593   \n",
       "11       0.239847    0.705708                0.239847           0.705708   \n",
       "12       0.121490   34.121526                0.121490          34.121526   \n",
       "13       0.453207  252.018585                0.453207         252.018585   \n",
       "14       0.032935    8.737445                0.032935           8.737445   \n",
       "\n",
       "    stack_level  can_infer  fit_order  \n",
       "0             3       True         15  \n",
       "1             2       True         11  \n",
       "2             2       True         13  \n",
       "3             2       True         10  \n",
       "4             2       True         12  \n",
       "5             2       True          9  \n",
       "6             2       True         14  \n",
       "7             1       True          2  \n",
       "8             2       True          8  \n",
       "9             1       True          1  \n",
       "10            1       True          5  \n",
       "11            1       True          7  \n",
       "12            1       True          4  \n",
       "13            1       True          3  \n",
       "14            1       True          6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(predictor_new_features.leaderboard(silent=True))\n",
    "except:\n",
    "    predictor_new_features = TabularPredictor.load('autogluon-new-features')\n",
    "    display(predictor_new_features.leaderboard(silent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new_features = predictor_new_features.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Setting up for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting negative predictions to zero\n",
    "predictions_new_features[predictions_new_features < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_new_features_df = pd.read_csv('../data/sampleSubmission.csv')\n",
    "submission_new_features_df['count'] = predictions_new_features\n",
    "submission_new_features_df.to_csv('submission-new-features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count_old</th>\n",
       "      <th>count_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>34.273094</td>\n",
       "      <td>23.911224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>43.230057</td>\n",
       "      <td>42.881252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>46.590622</td>\n",
       "      <td>47.045166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>50.979973</td>\n",
       "      <td>49.280098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>51.777607</td>\n",
       "      <td>51.790570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>2012-12-31 19:00:00</td>\n",
       "      <td>168.921830</td>\n",
       "      <td>158.083010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>2012-12-31 20:00:00</td>\n",
       "      <td>168.921830</td>\n",
       "      <td>158.083010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>2012-12-31 21:00:00</td>\n",
       "      <td>169.793330</td>\n",
       "      <td>148.362730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>2012-12-31 22:00:00</td>\n",
       "      <td>167.674060</td>\n",
       "      <td>144.396210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>2012-12-31 23:00:00</td>\n",
       "      <td>165.277770</td>\n",
       "      <td>145.070510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime   count_old   count_new\n",
       "0     2011-01-20 00:00:00   34.273094   23.911224\n",
       "1     2011-01-20 01:00:00   43.230057   42.881252\n",
       "2     2011-01-20 02:00:00   46.590622   47.045166\n",
       "3     2011-01-20 03:00:00   50.979973   49.280098\n",
       "4     2011-01-20 04:00:00   51.777607   51.790570\n",
       "...                   ...         ...         ...\n",
       "6488  2012-12-31 19:00:00  168.921830  158.083010\n",
       "6489  2012-12-31 20:00:00  168.921830  158.083010\n",
       "6490  2012-12-31 21:00:00  169.793330  148.362730\n",
       "6491  2012-12-31 22:00:00  167.674060  144.396210\n",
       "6492  2012-12-31 23:00:00  165.277770  145.070510\n",
       "\n",
       "[6493 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare old and new submissions\n",
    "submission_df = pd.read_csv('submission.csv')\n",
    "submission_new_features_df = pd.read_csv('submission-new-features.csv')\n",
    "\n",
    "submission_df.merge(submission_new_features_df, on='datetime', suffixes=('_old', '_new'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Submitting New Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L3'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = predictor_new_features.model_best\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 188k/188k [00:00<00:00, 436kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission-new-features.csv -m \"new features with {best_model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName                     date                 description                                status    publicScore  privateScore  \n",
      "---------------------------  -------------------  -----------------------------------------  --------  -----------  ------------  \n",
      "submission-new-features.csv  2024-07-08 23:47:44  new features with WeightedEnsemble_L3      complete  1.7966       1.7966        \n",
      "submission.csv               2024-07-07 21:14:45  first submission with WeightedEnsemble_L3  complete  1.84764      1.84764       \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Hyperparameter Tuning\n",
    "The following documentation show how to train a model with hyperparameter tuning using AutoGluon.\n",
    "\n",
    "Documentation: https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.fit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Transforming Features as Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Data Loader initialized with data path: ../data/\n",
      "            - Use load_raw() to load raw data\n",
      "            - Use get_train_test_data() to get raw train and test data  \n",
      "            - Use save_feature_engineered_data() to save feature engineered data\n",
      "            - Use load_feature_engineered() to load feature engineered data\n",
      "              \n",
      "            - Use set_as_category() to set columns as category\n",
      "\n",
      "        Checkpoints available: ['hyperparameter_tuning']\n",
      "        \n",
      "Columns ['season', 'weather'] set as category successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "season         category\n",
       "holiday           int64\n",
       "workingday        int64\n",
       "weather        category\n",
       "temp            float64\n",
       "humidity          int64\n",
       "windspeed       float64\n",
       "count             int64\n",
       "day_of_week       int64\n",
       "hour              int64\n",
       "minute            int64\n",
       "date             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to categorical for better performance\n",
    "loader = DataLoader()\n",
    "\n",
    "loader.load_feature_engineered(checkpoint_name='hyperparameter_tuning')\n",
    "loader.set_as_category(columns=[\"season\", \"weather\"])\n",
    "\n",
    "train_df, test_df = loader.get_train_test_data()\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Creating a Validation Set for Local Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Train shape: (8708, 12)\n",
      "Validation shape: (2178, 12)    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.88</td>\n",
       "      <td>83</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.90</td>\n",
       "      <td>39</td>\n",
       "      <td>19.9995</td>\n",
       "      <td>450</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.80</td>\n",
       "      <td>41</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>276</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.76</td>\n",
       "      <td>93</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>45</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  holiday  workingday weather   temp  humidity  windspeed  count  \\\n",
       "2815      3        0           1       1  27.88        83     6.0032     35   \n",
       "8695      3        0           0       1  36.90        39    19.9995    450   \n",
       "8406      3        0           1       1  32.80        41    16.9979    276   \n",
       "1543      2        0           0       2  14.76        93     7.0015      5   \n",
       "4952      4        0           0       1  13.12        45    16.9979    200   \n",
       "\n",
       "      day_of_week  hour  minute        date  \n",
       "2815            2     5       0  2011-07-06  \n",
       "8695            5    16       0  2012-08-04  \n",
       "8406            2    15       0  2012-07-11  \n",
       "1543            6     4       0  2011-04-10  \n",
       "4952            5    10       0  2011-11-19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\"\" \n",
    "Train shape: {train_val_df.shape}\n",
    "Validation shape: {val_df.shape}    \n",
    "\"\"\")\n",
    "\n",
    "train_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.62</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.10</td>\n",
       "      <td>54</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>48</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>163</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.52</td>\n",
       "      <td>62</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>233</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.42</td>\n",
       "      <td>53</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>222</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-06-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  holiday  workingday weather   temp  humidity  windspeed  count  \\\n",
       "3133      3        0           1       1  33.62        59     0.0000    127   \n",
       "5786      1        1           0       1   4.10        54     6.0032     13   \n",
       "5224      4        0           0       1   9.84        48    12.9980    163   \n",
       "8953      3        0           1       2  29.52        62    12.9980    233   \n",
       "8054      2        0           1       1  25.42        53    16.9979    222   \n",
       "\n",
       "      day_of_week  hour  minute        date  \n",
       "3133            1    11       0  2011-07-19  \n",
       "5786            0     6       0  2012-01-16  \n",
       "5224            6    18       0  2011-12-11  \n",
       "8953            2    10       0  2012-08-15  \n",
       "8054            4    23       0  2012-06-15  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>56</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  season  holiday  workingday weather   temp  humidity  windspeed  \\\n",
       "0      1        0           1       1  10.66        56    26.0027   \n",
       "1      1        0           1       1  10.66        56     0.0000   \n",
       "2      1        0           1       1  10.66        56     0.0000   \n",
       "3      1        0           1       1  10.66        56    11.0014   \n",
       "4      1        0           1       1  10.66        56    11.0014   \n",
       "\n",
       "   day_of_week  hour  minute        date  \n",
       "0            3     0       0  2011-01-20  \n",
       "1            3     1       0  2011-01-20  \n",
       "2            3     2       0  2011-01-20  \n",
       "3            3     3       0  2011-01-20  \n",
       "4            3     4       0  2011-01-20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Re-train with One Hot Encoding & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from autogluon.common import space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon-new-hpo\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.31.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter optimization time: 1.0 minutes\n",
      "Time limit: 3.0 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 1/20 [00:53<17:02, 53.81s/it]\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      " 10%|         | 2/20 [00:46<07:01, 23.41s/it]\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "  5%|         | 1/20 [00:48<15:12, 48.00s/it]\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "  5%|         | 1/20 [00:53<17:04, 53.90s/it]\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      " 10%|         | 2/20 [00:45<06:53, 22.99s/it]\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "  5%|         | 1/20 [00:50<16:07, 50.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x32276b350>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'NN_TORCH': {'num_epochs': 10, 'activation': 'relu', 'dropout_prob': space.Real(0.0, 0.5)},\n",
    "    'GBM': {'num_boost_round': 1000, 'learning_rate': space.Real(0.01, 0.1, log=True)},\n",
    "    'XGB': {'n_estimators': 1000, 'learning_rate': space.Real(0.01, 0.1, log=True)}\n",
    "}\n",
    "\n",
    "\n",
    "hyper_timeout = 1 * 60  # seconds\n",
    "time_limit = 3 * 60\n",
    "print(f\"Hyperparameter optimization time: {hyper_timeout/60} minutes\")\n",
    "print(f\"Time limit: {time_limit/60} minutes\")\n",
    "\n",
    "# Custom hyperparameter tuning configuration\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'num_trials': 20,  # Number of trials to run\n",
    "    'scheduler': 'local',  # Scheduler to use for parallel training\n",
    "    'searcher': 'bayes',  # Searcher to use for hyperparameter optimization\n",
    "    'time_out': hyper_timeout,  # Time limit in seconds for each call to the ML model\n",
    "}\n",
    "\n",
    "predictor_new_hpo = TabularPredictor(\n",
    "    label='count',\n",
    "    path='autogluon-new-hpo',\n",
    "    eval_metric='root_mean_squared_error'    \n",
    ")\n",
    "\n",
    "predictor_new_hpo.fit(\n",
    "    train_val_df,\n",
    "    time_limit=time_limit,\n",
    "    presets='best_quality',\n",
    "    hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "    num_cpus=6,\n",
    "    num_gpus=1,\n",
    "    num_stack_levels=3,\n",
    "    verbosity=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-34.082446</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.436478</td>\n",
       "      <td>86.309923</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L5</td>\n",
       "      <td>-34.082446</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.436618</td>\n",
       "      <td>86.303996</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>-34.504071</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>30.725503</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>30.725503</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_BAG_L1/T3</td>\n",
       "      <td>-35.842340</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>19.883079</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>19.883079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost_BAG_L1/T2</td>\n",
       "      <td>-36.045101</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>12.522853</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>12.522853</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>-37.761090</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.124463</td>\n",
       "      <td>23.164374</td>\n",
       "      <td>0.124463</td>\n",
       "      <td>23.164374</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L1/T1</td>\n",
       "      <td>-39.337629</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>13.572753</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>13.572753</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T2</td>\n",
       "      <td>-77.096832</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>35.064095</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>35.064095</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>-113.980426</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.081503</td>\n",
       "      <td>15.827772</td>\n",
       "      <td>0.081503</td>\n",
       "      <td>15.827772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model   score_val              eval_metric  \\\n",
       "0       WeightedEnsemble_L2  -34.082446  root_mean_squared_error   \n",
       "1       WeightedEnsemble_L5  -34.082446  root_mean_squared_error   \n",
       "2        LightGBM_BAG_L1/T2  -34.504071  root_mean_squared_error   \n",
       "3         XGBoost_BAG_L1/T3  -35.842340  root_mean_squared_error   \n",
       "4         XGBoost_BAG_L1/T2  -36.045101  root_mean_squared_error   \n",
       "5        LightGBM_BAG_L1/T1  -37.761090  root_mean_squared_error   \n",
       "6         XGBoost_BAG_L1/T1  -39.337629  root_mean_squared_error   \n",
       "7  NeuralNetTorch_BAG_L1/T2  -77.096832  root_mean_squared_error   \n",
       "8  NeuralNetTorch_BAG_L1/T1 -113.980426  root_mean_squared_error   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0       0.436478  86.309923                0.000210           0.014114   \n",
       "1       0.436618  86.303996                0.000349           0.008187   \n",
       "2       0.078709  30.725503                0.078709          30.725503   \n",
       "3       0.136838  19.883079                0.136838          19.883079   \n",
       "4       0.096258  12.522853                0.096258          12.522853   \n",
       "5       0.124463  23.164374                0.124463          23.164374   \n",
       "6       0.100144  13.572753                0.100144          13.572753   \n",
       "7       0.078298  35.064095                0.078298          35.064095   \n",
       "8       0.081503  15.827772                0.081503          15.827772   \n",
       "\n",
       "   stack_level  can_infer  fit_order  \n",
       "0            2       True          8  \n",
       "1            5       True          9  \n",
       "2            1       True          2  \n",
       "3            1       True          5  \n",
       "4            1       True          4  \n",
       "5            1       True          1  \n",
       "6            1       True          3  \n",
       "7            1       True          7  \n",
       "8            1       True          6  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_new_hpo.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -32.49807779184623,\n",
       " 'mean_squared_error': -1056.1250601648892,\n",
       " 'mean_absolute_error': -19.817492352940548,\n",
       " 'r2': 0.9680029353683928,\n",
       " 'pearsonr': 0.9838875781242997,\n",
       " 'median_absolute_error': -11.453035354614258}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = predictor_new_hpo.evaluate(val_df)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new_hpo = predictor_new_hpo.predict(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative predictions with zero\n",
    "predictions_new_hpo[predictions_new_hpo < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1248213271145344"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating scores of predictions\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "mean_squared_log_error(val_df[\"count\"], predictions_new_hpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Loading the Best Model and Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is WeightedEnsemble_L2\n"
     ]
    }
   ],
   "source": [
    "best_model = predictor_new_hpo.model_best\n",
    "print(f\"The best model is {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-34.082446</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.436478</td>\n",
       "      <td>86.309923</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L5</td>\n",
       "      <td>-34.082446</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.436618</td>\n",
       "      <td>86.303996</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1/T2</td>\n",
       "      <td>-34.504071</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>30.725503</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>30.725503</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_BAG_L1/T3</td>\n",
       "      <td>-35.842340</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>19.883079</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>19.883079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost_BAG_L1/T2</td>\n",
       "      <td>-36.045101</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>12.522853</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>12.522853</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L1/T1</td>\n",
       "      <td>-37.761090</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.124463</td>\n",
       "      <td>23.164374</td>\n",
       "      <td>0.124463</td>\n",
       "      <td>23.164374</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L1/T1</td>\n",
       "      <td>-39.337629</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>13.572753</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>13.572753</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T2</td>\n",
       "      <td>-77.096832</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>35.064095</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>35.064095</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetTorch_BAG_L1/T1</td>\n",
       "      <td>-113.980426</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.081503</td>\n",
       "      <td>15.827772</td>\n",
       "      <td>0.081503</td>\n",
       "      <td>15.827772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model   score_val              eval_metric  \\\n",
       "0       WeightedEnsemble_L2  -34.082446  root_mean_squared_error   \n",
       "1       WeightedEnsemble_L5  -34.082446  root_mean_squared_error   \n",
       "2        LightGBM_BAG_L1/T2  -34.504071  root_mean_squared_error   \n",
       "3         XGBoost_BAG_L1/T3  -35.842340  root_mean_squared_error   \n",
       "4         XGBoost_BAG_L1/T2  -36.045101  root_mean_squared_error   \n",
       "5        LightGBM_BAG_L1/T1  -37.761090  root_mean_squared_error   \n",
       "6         XGBoost_BAG_L1/T1  -39.337629  root_mean_squared_error   \n",
       "7  NeuralNetTorch_BAG_L1/T2  -77.096832  root_mean_squared_error   \n",
       "8  NeuralNetTorch_BAG_L1/T1 -113.980426  root_mean_squared_error   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0       0.436478  86.309923                0.000210           0.014114   \n",
       "1       0.436618  86.303996                0.000349           0.008187   \n",
       "2       0.078709  30.725503                0.078709          30.725503   \n",
       "3       0.136838  19.883079                0.136838          19.883079   \n",
       "4       0.096258  12.522853                0.096258          12.522853   \n",
       "5       0.124463  23.164374                0.124463          23.164374   \n",
       "6       0.100144  13.572753                0.100144          13.572753   \n",
       "7       0.078298  35.064095                0.078298          35.064095   \n",
       "8       0.081503  15.827772                0.081503          15.827772   \n",
       "\n",
       "   stack_level  can_infer  fit_order  \n",
       "0            2       True          8  \n",
       "1            5       True          9  \n",
       "2            1       True          2  \n",
       "3            1       True          5  \n",
       "4            1       True          4  \n",
       "5            1       True          1  \n",
       "6            1       True          3  \n",
       "7            1       True          7  \n",
       "8            1       True          6  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_predictor = TabularPredictor.load('autogluon-new-hpo')\n",
    "saved_predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_tunning_prediction_df = saved_predictor.predict(test_df)\n",
    "\n",
    "# Replace negative predictions with zero\n",
    "hyper_tunning_prediction_df[hyper_tunning_prediction_df < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Submitting the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 188k/188k [00:00<00:00, 381kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "# submission\n",
    "submission_hyper_tunning_df = pd.read_csv('../data/sampleSubmission.csv')\n",
    "submission_hyper_tunning_df['count'] = hyper_tunning_prediction_df\n",
    "submission_hyper_tunning_df.to_csv('submission-hyper-tunning.csv', index=False)\n",
    "\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submission-hyper-tunning.csv -m \"hyperparameter tunning with {best_model}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including Custom Models on Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Data Loader initialized with data path: ../data/\n",
      "            - Use load_raw() to load raw data\n",
      "            - Use get_train_test_data() to get raw train and test data  \n",
      "            - Use save_feature_engineered_data() to save feature engineered data\n",
      "            - Use load_feature_engineered() to load feature engineered data\n",
      "              \n",
      "            - Use set_as_category() to set columns as category\n",
      "\n",
      "        Checkpoints available: ['hyperparameter_tuning']\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns ['season', 'weather'] set as category successfully!\n"
     ]
    }
   ],
   "source": [
    "loader.load_feature_engineered(checkpoint_name='hyperparameter_tuning')\n",
    "loader.set_as_category(columns=[\"season\", \"weather\"])\n",
    "\n",
    "train_df, test_df = loader.get_train_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Creating Validation Set for Local Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Train shape: (8708, 12)\n",
      "Validation shape: (2178, 12)  \n",
      "Test shape: (6493, 11)  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.88</td>\n",
       "      <td>83</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.90</td>\n",
       "      <td>39</td>\n",
       "      <td>19.9995</td>\n",
       "      <td>450</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.80</td>\n",
       "      <td>41</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>276</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.76</td>\n",
       "      <td>93</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>45</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  holiday  workingday weather   temp  humidity  windspeed  count  \\\n",
       "2815      3        0           1       1  27.88        83     6.0032     35   \n",
       "8695      3        0           0       1  36.90        39    19.9995    450   \n",
       "8406      3        0           1       1  32.80        41    16.9979    276   \n",
       "1543      2        0           0       2  14.76        93     7.0015      5   \n",
       "4952      4        0           0       1  13.12        45    16.9979    200   \n",
       "\n",
       "      day_of_week  hour  minute        date  \n",
       "2815            2     5       0  2011-07-06  \n",
       "8695            5    16       0  2012-08-04  \n",
       "8406            2    15       0  2012-07-11  \n",
       "1543            6     4       0  2011-04-10  \n",
       "4952            5    10       0  2011-11-19  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\"\" \n",
    "Train shape: {train_val_df.shape}\n",
    "Validation shape: {val_df.shape}  \n",
    "Test shape: {test_df.shape}  \n",
    "\"\"\")\n",
    "\n",
    "train_val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   5.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   5.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   5.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   5.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   5.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   5.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   5.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   8.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   8.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   8.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   9.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=  10.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel/anaconda3/envs/bikeshare/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   8.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   8.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   8.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   8.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   9.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   9.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   8.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   5.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   7.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   8.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   8.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   8.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   9.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   7.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 5.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 5.3min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 5.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 5.3min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 5.3min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 5.3min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 5.3min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 5.3min\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   5.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   5.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=55.4min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=55.4min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=55.5min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=55.5min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=55.5min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=55.4min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=55.5min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=55.5min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   5.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=28.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=28.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=28.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=28.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=28.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=28.2min\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=28.2min\n",
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Import random forest regressor, grid search and random search\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(train_val_df.drop(columns=['count', 'date']), train_val_df['count'])\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_log_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m predictions[predictions \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculating scores of predictions\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmean_squared_log_error\u001b[49m(val_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m], predictions), r2_score(val_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m], predictions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_log_error' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "predictions = grid_search.predict(val_df.drop(columns=['count', 'date']))\n",
    "\n",
    "# Replace negative predictions with zero\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "# Calculating scores of predictions\n",
    "mean_squared_log_error(val_df[\"count\"], predictions), r2_score(val_df[\"count\"], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   3.9s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   7.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.9s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.7s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   6.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   4.4s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   4.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.6s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.5s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.4s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   6.3s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "random_search.fit(train_val_df.drop(columns=['count', 'date']), train_val_df['count'])\n",
    "\n",
    "print(f\"Best parameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17183809433125152, 0.8607013620248639)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "predictions = random_search.predict(val_df.drop(columns=['count', 'date']))\n",
    "\n",
    "# Replace negative predictions with zero\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "# Calculating scores of predictions\n",
    "mean_squared_log_error(val_df[\"count\"], predictions), r2_score(val_df[\"count\"], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Personal Cross Validated SARIMAX Model Wrapper\n",
    "> https://github.com/samlexrod/cvsarimax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikeshare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
